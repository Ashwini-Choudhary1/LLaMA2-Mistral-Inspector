GENERATION_CONFIG = {
    "temperature": 0.7,
    "max_new_tokens": 256,
    "top_p": 0.9
}

MODELS = {
    "llama": {
        "name": "llama",
        "type": "gguf"
    },
    "mistral": {
        "name": "mistral",
        "type": "gguf"
    }
}
